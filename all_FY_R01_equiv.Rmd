---
title: "all_years"
author: "Nick_Fox"
date: "February 16, 2016"
output: html_document
---

```{r echo = FALSE}
#install.packages("dplyr")
#install.packages("ggplot2")
#install.packages("tidyr")
#install.packages("data.table")
#install.packages("stringr")
#install.packages("ineq")
#install.packages("RColorBrewer")
#install.packages("scales")
#install.packages("quantmod")
#install.packages("lubridate")
#install.packages("data.table")

library(dplyr)
library(tidyr)
library(ggplot2)
library(data.table)
library(stringr)
library(ineq)
library(RColorBrewer)
library(scales)
library(grid)
library(quantmod)
library(lubridate)
library(data.table)
#loads in all packages used in this analysis.  Find install code above.

```

```{r echo = FALSE}
Sem <- function(x) {
  sqrt(var(x)/length(x))
  }
#creates function to calculate the standard error of the mean, SEM




summarySE <- function(data=NULL, measurevar, groupvars=NULL, na.rm=FALSE,
                      conf.interval=.95, .drop=TRUE) {
    library(plyr)

    # New version of length which can handle NA's: if na.rm==T, don't count them
    length2 <- function (x, na.rm=FALSE) {
        if (na.rm) sum(!is.na(x))
        else       length(x)
    }

    # This does the summary. For each group's data frame, return a vector with
    # N, mean, and sd
    datac <- ddply(data, groupvars, .drop=.drop,
      .fun = function(xx, col) {
        c(N    = length2(xx[[col]], na.rm=na.rm),
          mean = mean   (xx[[col]], na.rm=na.rm),
          sd   = sd     (xx[[col]], na.rm=na.rm)
        )
      },
      measurevar
    )

    # Rename the "mean" column    
    datac <- rename(datac, c("mean" = measurevar))

    datac$se <- datac$sd / sqrt(datac$N)  # Calculate standard error of the mean

    # Confidence interval multiplier for standard error
    # Calculate t-statistic for confidence interval: 
    # e.g., if conf.interval is .95, use .975 (above/below), and use df=N-1
    ciMult <- qt(conf.interval/2 + .5, datac$N-1)
    datac$ci <- datac$se * ciMult

    return(datac)
}


normDataWithin <- function(data=NULL, idvar, measurevar, betweenvars=NULL,
                           na.rm=FALSE, .drop=TRUE) {
    library(plyr)

    # Measure var on left, idvar + between vars on right of formula.
    data.subjMean <- ddply(data, c(idvar, betweenvars), .drop=.drop,
     .fun = function(xx, col, na.rm) {
        c(subjMean = mean(xx[,col], na.rm=na.rm))
      },
      measurevar,
      na.rm
    )

    # Put the subject means with original data
    data <- merge(data, data.subjMean)

    # Get the normalized data in a new column
    measureNormedVar <- paste(measurevar, "_norm", sep="")
    data[,measureNormedVar] <- data[,measurevar] - data[,"subjMean"] +
                               mean(data[,measurevar], na.rm=na.rm)

    # Remove this subject mean column
    data$subjMean <- NULL

    return(data)
}


summarySEwithin <- function(data=NULL, measurevar, betweenvars=NULL, withinvars=NULL,
                            idvar=NULL, na.rm=FALSE, conf.interval=.95, .drop=TRUE) {

  # Ensure that the betweenvars and withinvars are factors
  factorvars <- vapply(data[, c(betweenvars, withinvars), drop=FALSE],
    FUN=is.factor, FUN.VALUE=logical(1))

  if (!all(factorvars)) {
    nonfactorvars <- names(factorvars)[!factorvars]
    message("Automatically converting the following non-factors to factors: ",
            paste(nonfactorvars, collapse = ", "))
    data[nonfactorvars] <- lapply(data[nonfactorvars], factor)
  }

  # Get the means from the un-normed data
  datac <- summarySE(data, measurevar, groupvars=c(betweenvars, withinvars),
                     na.rm=na.rm, conf.interval=conf.interval, .drop=.drop)

  # Drop all the unused columns (these will be calculated with normed data)
  datac$sd <- NULL
  datac$se <- NULL
  datac$ci <- NULL

  # Norm each subject's data
  ndata <- normDataWithin(data, idvar, measurevar, betweenvars, na.rm, .drop=.drop)

  # This is the name of the new column
  measurevar_n <- paste(measurevar, "_norm", sep="")

  # Collapse the normed data - now we can treat between and within vars the same
  ndatac <- summarySE(ndata, measurevar_n, groupvars=c(betweenvars, withinvars),
                      na.rm=na.rm, conf.interval=conf.interval, .drop=.drop)

  # Apply correction from Morey (2008) to the standard error and confidence interval
  #  Get the product of the number of conditions of within-S variables
  nWithinGroups    <- prod(vapply(ndatac[,withinvars, drop=FALSE], FUN=nlevels,
                           FUN.VALUE=numeric(1)))
  correctionFactor <- sqrt( nWithinGroups / (nWithinGroups-1) )

  # Apply the correction factor
  ndatac$sd <- ndatac$sd * correctionFactor
  ndatac$se <- ndatac$se * correctionFactor
  ndatac$ci <- ndatac$ci * correctionFactor

  # Combine the un-normed means with the normed results
  merge(datac, ndatac)
}

asNumeric <- function(x) as.numeric(as.character(x))
factorsNumeric <- function(d) modifyList(d, lapply(d[, sapply(d, is.factor)],   
                                                   asNumeric))
#functions that allow easy conversions of factors to numeric
```

```{r echo = FALSE}
read.url <- function(url, ...){
  tmpFile <- tempfile()
  download.file(url, destfile = tmpFile, method = "curl")
  url.data <- fread(tmpFile, ...)
  return(url.data)
}

```


```{r echo = FALSE}

fte_theme <- function() {
      
      # Generate the colors for the chart procedurally with RColorBrewer
      palette <- brewer.pal("Greys", n=9)
      color.background = palette[2]
      color.grid.major = palette[3]
      color.axis.text = palette[6]
      color.axis.title = palette[7]
      color.title = palette[9]
      
      # Begin construction of chart
      theme_bw(base_size=9) +
        
      # Set the entire chart region to a light gray color
      theme(panel.background=element_rect(fill=color.background, color=color.background)) +
      theme(plot.background=element_rect(fill=color.background, color=color.background)) +
      theme(panel.border=element_rect(color=color.background)) +
      
      # Format the grid
      theme(panel.grid.major=element_line(color=color.grid.major,size=.25)) +
      theme(panel.grid.minor=element_blank()) +
      theme(axis.ticks=element_blank()) +
      
      # Format the legend, but hide by default
      #theme(legend.position="none") +
      theme(legend.background = element_rect(fill=color.background)) +
      theme(legend.text = element_text(size=10,color=color.axis.title)) +
      
      # Set title and axis labels, and format these and tick marks
      theme(plot.title=element_text(color=color.title, size=16, vjust=1.25)) +
      theme(axis.text.x=element_text(size=10,color=color.axis.text)) +
      theme(axis.text.y=element_text(size=10,color=color.axis.text)) +
      theme(axis.title.x=element_text(size=12,color=color.axis.title, vjust=0.5)) +
      theme(axis.title.y=element_text(size=12,color=color.axis.title, vjust=0.5)) +
      
      # Plot margins
      theme(plot.margin = unit(c(0.35, 0.2, 0.3, 0.35), "cm"))
    }

```

```{r echo = FALSE}
#FOR MAC, use the WD below:
setwd("~/Dropbox/GitHub_master/data/NIH_awards")

```

```{r echo = FALSE}

fy2014 <- read.csv("RePORTER_PRJ_C_FY2014.csv", header = TRUE, stringsAsFactors = FALSE)
fy2013 <- read.csv("RePORTER_PRJ_C_FY2013.csv", header = TRUE, stringsAsFactors = FALSE)
fy2012 <- read.csv("RePORTER_PRJ_C_FY2012.csv", header = TRUE, stringsAsFactors = FALSE)
fy2011 <- read.csv("RePORTER_PRJ_C_FY2011.csv", header = TRUE, stringsAsFactors = FALSE)
fy2010 <- read.csv("RePORTER_PRJ_C_FY2010.csv", header = TRUE, stringsAsFactors = FALSE)
fy2009 <- read.csv("RePORTER_PRJ_C_FY2009.csv", header = TRUE, stringsAsFactors = FALSE)
fy2008 <- read.csv("RePORTER_PRJ_C_FY2008.csv", header = TRUE, stringsAsFactors = FALSE)
fy2007 <- read.csv("RePORTER_PRJ_C_FY2007.csv", header = TRUE, stringsAsFactors = FALSE)
fy2006 <- read.csv("RePORTER_PRJ_C_FY2006.csv", header = TRUE, stringsAsFactors = FALSE)
fy2005 <- read.csv("RePORTER_PRJ_C_FY2005.csv", header = TRUE, stringsAsFactors = FALSE)
fy2004 <- read.csv("RePORTER_PRJ_C_FY2004.csv", header = TRUE, stringsAsFactors = FALSE)
fy2003 <- read.csv("RePORTER_PRJ_C_FY2003.csv", header = TRUE, stringsAsFactors = FALSE)
fy2002 <- read.csv("RePORTER_PRJ_C_FY2002.csv", header = TRUE, stringsAsFactors = FALSE)
fy2001 <- read.csv("RePORTER_PRJ_C_FY2001.csv", header = TRUE, stringsAsFactors = FALSE)
fy2000 <- read.csv("RePORTER_PRJ_C_FY2000.csv", header = TRUE, stringsAsFactors = FALSE)

#read in all of the raw data

```


```{r echo = FALSE}
filter_target <- c("R01", "R23", "R29", "R37")

fy2014 <- fy2014 %>% 
  filter(ACTIVITY %in% filter_target) %>% 
  select(FY, ACTIVITY, APPLICATION_ID, PI_IDS, TOTAL_COST)

fy2013 <- fy2013 %>% 
  filter(ACTIVITY %in% filter_target) %>% 
  select(FY, ACTIVITY, APPLICATION_ID, PI_IDS, TOTAL_COST)

fy2012 <- fy2012 %>% 
  filter(ACTIVITY %in% filter_target) %>% 
  select(FY, ACTIVITY, APPLICATION_ID, PI_IDS, TOTAL_COST)

fy2011 <- fy2011 %>% 
  filter(ACTIVITY %in% filter_target) %>% 
  select(FY, ACTIVITY, APPLICATION_ID, PI_IDS, TOTAL_COST)

fy2010 <- fy2010 %>% 
  filter(ACTIVITY %in% filter_target) %>% 
  select(FY, ACTIVITY, APPLICATION_ID, PI_IDS, TOTAL_COST)

fy2009 <- fy2009 %>% 
  filter(ACTIVITY %in% filter_target) %>% 
  select(FY, ACTIVITY, APPLICATION_ID, PI_IDS, TOTAL_COST)

fy2008 <- fy2008 %>% 
  filter(ACTIVITY %in% filter_target) %>% 
  select(FY, ACTIVITY, APPLICATION_ID, PI_IDS, TOTAL_COST)

fy2007 <- fy2007 %>% 
  filter(ACTIVITY %in% filter_target) %>% 
  select(FY, ACTIVITY, APPLICATION_ID, PI_IDS, TOTAL_COST)

fy2006 <- fy2006 %>% 
  filter(ACTIVITY %in% filter_target) %>% 
  select(FY, ACTIVITY, APPLICATION_ID, PI_IDS, TOTAL_COST)

fy2005 <- fy2005 %>% 
  filter(ACTIVITY %in% filter_target) %>% 
  select(FY, ACTIVITY, APPLICATION_ID, PI_IDS, TOTAL_COST)

fy2004 <- fy2004 %>% 
  filter(ACTIVITY %in% filter_target) %>% 
  select(FY, ACTIVITY, APPLICATION_ID, PI_IDS, TOTAL_COST)

fy2003 <- fy2003 %>% 
  filter(ACTIVITY %in% filter_target) %>% 
  select(FY, ACTIVITY, APPLICATION_ID, PI_IDS, TOTAL_COST)

fy2002 <- fy2002 %>% 
  filter(ACTIVITY %in% filter_target) %>% 
  select(FY, ACTIVITY, APPLICATION_ID, PI_IDS, TOTAL_COST)

fy2001 <- fy2001 %>% 
  filter(ACTIVITY %in% filter_target) %>% 
  select(FY, ACTIVITY, APPLICATION_ID, PI_IDS, TOTAL_COST)

fy2000 <- fy2000 %>% 
  filter(ACTIVITY %in% filter_target) %>% 
  select(FY, ACTIVITY, APPLICATION_ID, PI_IDS, TOTAL_COST)

#select only R01 equivalent awards and the relevent columns
```

``` {r echo = FALSE}

R01_equiv <- bind_rows(fy2014, fy2013, fy2012, fy2011, fy2010, fy2009, fy2008, fy2007, fy2006, fy2005, fy2004, fy2003, fy2002, fy2001, fy2000)

#bind all years into one data frame

```

```{r echo = FALSE}

R01_equiv <- R01_equiv %>% 
  separate(col = PI_IDS, into = c("PI_1", "PI_2", "PI_3", "PI_4", "PI_5", "PI_6", "PI_7", "PI_8", "PI_9", "PI_10", "PI_11"), sep = "\\;")

R01_equiv[R01_equiv == ""] <- NA

R01_equiv <- as.data.frame(sapply(R01_equiv, gsub, pattern = "(.contact.)", replacement = ""), stringsAsFactors = FALSE)

R01_equiv$TOTAL_COST <- as.numeric(as.character(R01_equiv$TOTAL_COST))

R01_equiv <- R01_equiv %>% 
  mutate(PI_1_DUMMY = ifelse(!is.na(PI_1), 1, 0), PI_2_DUMMY = ifelse(!is.na(PI_2), 1, 0), PI_3_DUMMY = ifelse(!is.na(PI_3), 1, 0), PI_4_DUMMY = ifelse(!is.na(PI_4), 1, 0), PI_5_DUMMY = ifelse(!is.na(PI_5), 1, 0), PI_6_DUMMY = ifelse(!is.na(PI_6), 1, 0), PI_7_DUMMY = ifelse(!is.na(PI_7), 1, 0), PI_8_DUMMY = ifelse(!is.na(PI_8), 1, 0), PI_9_DUMMY = ifelse(!is.na(PI_9), 1, 0), PI_10_DUMMY = ifelse(!is.na(PI_10), 1, 0), PI_11_DUMMY = ifelse(!is.na(PI_11), 1, 0), TOTAL_PIS = PI_1_DUMMY + PI_2_DUMMY + PI_3_DUMMY + PI_4_DUMMY + PI_5_DUMMY + PI_6_DUMMY + PI_7_DUMMY + PI_8_DUMMY + PI_9_DUMMY + PI_10_DUMMY + PI_11_DUMMY)

R01_equiv <- R01_equiv %>%
  group_by(FY) %>% 
  filter(!is.na(TOTAL_COST)) %>% 
  mutate(TOTAL_DOLLARS = sum(TOTAL_COST), AVERAGE_PER_PI = TOTAL_DOLLARS / sum(TOTAL_PIS))

R01_equiv <- R01_equiv %>% 
  group_by(FY, APPLICATION_ID) %>% 
  mutate(COST_PER_PI = TOTAL_COST / TOTAL_PIS)

R01_equiv <- R01_equiv %>% 
  group_by(FY) %>% 
  mutate(PERCENT_COST_PER_PI = (COST_PER_PI / TOTAL_DOLLARS) * 100)

#seperating out PI column and calculating cost per PI per FY, average per PI per FY

```

```{r echo = FALSE}

PI_1 <- R01_equiv %>%
  mutate(PI = PI_1) %>%
  group_by(FY, PI) %>% 
  select(FY, ACTIVITY, PI, COST_PER_PI, PERCENT_COST_PER_PI)

PI_2 <- R01_equiv %>%
  filter(!is.na(PI_2)) %>% 
  mutate(PI = PI_2) %>%
  group_by(FY, PI) %>% 
  select(FY, ACTIVITY, PI, COST_PER_PI, PERCENT_COST_PER_PI)

PI_3 <- R01_equiv %>% 
  filter(!is.na(PI_3)) %>%
  mutate(PI = PI_3) %>%
  group_by(FY, PI) %>% 
  select(FY, ACTIVITY, PI, COST_PER_PI, PERCENT_COST_PER_PI)

PI_4 <- R01_equiv %>% 
  filter(!is.na(PI_4)) %>%
  mutate(PI = PI_4) %>%
  group_by(FY, PI) %>% 
  select(FY, ACTIVITY, PI, COST_PER_PI, PERCENT_COST_PER_PI)

PI_5 <- R01_equiv %>% 
  filter(!is.na(PI_5)) %>%
  mutate(PI = PI_5) %>%
  group_by(FY, PI) %>% 
  select(FY, ACTIVITY, PI, COST_PER_PI, PERCENT_COST_PER_PI)

PI_6 <- R01_equiv %>% 
  filter(!is.na(PI_6)) %>%
  mutate(PI = PI_6) %>% 
  group_by(FY, PI) %>% 
  select(FY, ACTIVITY, PI, COST_PER_PI, PERCENT_COST_PER_PI)

PI_7 <- R01_equiv %>% 
  filter(!is.na(PI_7)) %>%
  mutate(PI = PI_7) %>%
  group_by(FY, PI) %>% 
  select(FY, ACTIVITY, PI, COST_PER_PI, PERCENT_COST_PER_PI)

PI_8 <- R01_equiv %>% 
  filter(!is.na(PI_8)) %>%
  mutate(PI = PI_8) %>%
  group_by(FY, PI) %>% 
  select(FY, ACTIVITY, PI, COST_PER_PI, PERCENT_COST_PER_PI)

PI_9 <- R01_equiv %>% 
  filter(!is.na(PI_9)) %>%
  mutate(PI = PI_9) %>% 
  group_by(FY, PI) %>% 
  select(FY, ACTIVITY, PI, COST_PER_PI, PERCENT_COST_PER_PI)

PI_10 <- R01_equiv %>% 
  filter(!is.na(PI_10)) %>%
  mutate(PI = PI_10) %>%
  group_by(FY, PI) %>% 
  select(FY, ACTIVITY, PI, COST_PER_PI, PERCENT_COST_PER_PI)

PI_ALL <- bind_rows(PI_1, PI_2, PI_3, PI_4, PI_5, PI_6, PI_7, PI_8, PI_9, PI_10)

#get all authors, regardless of position in grant, into one column for further analysis
```

```{r echo = FALSE}

PI_ALL <- PI_ALL %>%
  group_by(FY, PI) %>% 
  mutate(SUM_COST_RECEIVED = sum(COST_PER_PI), NUMBER_OF_GRANTS = n(), SUM_PERCENT_RECEIVED = sum(PERCENT_COST_PER_PI)) %>% 
  distinct(PI)

#data frame with each author only appearing once per fiscal year.
```

```{r echo = FALSE}

quantiles <- PI_ALL %>% 
  group_by(FY) %>% 
  mutate(quantile = ntile(SUM_COST_RECEIVED, 5), grant_dummy = ifelse(NUMBER_OF_GRANTS == 1, 1, 2))

quantiles_average <- quantiles %>% 
  group_by(FY, quantile) %>% 
  mutate(average_sum_percent = mean(SUM_PERCENT_RECEIVED)) %>% 
  distinct(FY)


quantiles <- quantiles %>% 
  group_by(FY) %>% 
  mutate(FY_Gini = Gini(SUM_COST_RECEIVED))

quantiles_Gini <- quantiles %>% 
  distinct(FY)

```

```{r echo = FALSE}

quantiles_test <- quantiles %>% 
  filter(NUMBER_OF_GRANTS == 1) %>% 
  group_by(FY) %>% 
  mutate(average_cost_one_grant = mean(SUM_COST_RECEIVED)) %>% 
  distinct(FY)
```

```{r echo = FALSE}

monthly_cpi <-read.csv("CPIAUCSL.csv", header = TRUE, stringsAsFactors = FALSE)

monthly_cpi$FY <- year(monthly_cpi$DATE)

yearly_cpi <- monthly_cpi %>% 
  group_by(FY) %>% 
  summarize(cpi = mean(VALUE))

yearly_cpi$adj_factor <- yearly_cpi$cpi/yearly_cpi$cpi[yearly_cpi$FY == 2000]

yearly_cpi$FY <- as.numeric(yearly_cpi$FY)

quantiles_test$FY <- as.numeric(quantiles_test$FY)


quantiles_test <- dplyr::left_join(quantiles_test, yearly_cpi, by = "FY")

quantiles_test$adj_factor <- 2-quantiles_test$adj_factor

quantiles_test <- quantiles_test %>% 
  mutate(adjusted_average_cost = average_cost_one_grant * adj_factor)

#creates the adjustment factor for the quantiles_test data frame using the Consumer Price Index (CPI)
```

```{R echo = FALSE}

R01_equiv_test <- R01_equiv %>% 
  distinct(FY)
 
R01_equiv_test$FY <- as.numeric(R01_equiv_test$FY)

R01_equiv_test <- dplyr::left_join(R01_equiv_test, yearly_cpi, by = "FY")

R01_equiv_test$adj_factor <- 2-R01_equiv_test$adj_factor

R01_equiv_test <- R01_equiv_test %>% 
  mutate(adjusted_total_dollars = TOTAL_DOLLARS * adj_factor) %>% 
  select(FY, TOTAL_DOLLARS, adjusted_total_dollars)

```


```{r echo = FALSE}

quantiles_Gini %>% 
  ggplot(aes(x = FY, y = FY_Gini, group = 1)) + geom_line(size = 2, colour = "#c0392b") + coord_cartesian(ylim = c(0.3, 0.36)) + fte_theme() + labs(title="Gini coefficient within R01-equivelent awards\n2000 - 2014", x="\nFiscal Year", y="Gini coefficient\n") + geom_hline(yintercept=0.3, size=0.4, color="black")
```

```{r echo = FALSE}

quantiles_test$FY <- as.factor(quantiles_test$FY)

quantiles_test %>% 
  ggplot(aes(x = FY, y = average_cost_one_grant, group = 1)) + geom_line(size = 2, colour = "#c0392b") + geom_line(aes(y = adjusted_average_cost), size = 2, colour = "blue") + fte_theme() + labs(title="Average amount dispersed to investigators\nwith 1 R01 equivalent award", x="\nFiscal Year", y="Average dollars\n") + geom_hline(yintercept=200000, size=0.4, color="black") + coord_cartesian(ylim = c(200000, 400000))

#average amount of grant dollars going to investigators who are only receiving one grant
```

```{r echo = FALSE}

R01_equiv_test$FY <- as.factor(R01_equiv_test$FY)

R01_equiv_test %>% 
  ggplot(aes(x = FY, y = TOTAL_DOLLARS, group = 1)) + geom_line(size = 2, colour = "#c0392b") + geom_line(aes(y = adjusted_total_dollars), size = 2, colour = "blue") + fte_theme() + labs(title="Amount dispersed by NIH per year for\nR01-equivalent awards", x="\nFiscal Year", y="Dollars\n") + geom_hline(yintercept=6000000000, size=0.4, color="black") + geom_line(colour = "red") + geom_line(aes(y = adjusted_total_dollars), colour = "blue")

```


```{r echo = FALSE}

quantiles_average %>%
  ggplot(aes(x = FY, y = average_sum_percent, group = quantile)) + geom_line(aes(colour = factor(quantile)), size = 2) + fte_theme() + labs(title="Percent of total awarded dollars per investigator\ngrouped by quantile", x="\nFiscal Year", y="Percent of awarded dollars\n") + geom_hline(yintercept=0.001, size=0.4, color="black") + scale_color_brewer(palette = "Set1")

```

```{r echo = FALSE}

quantiles %>% 
  ggplot(aes(x = FY, y = SUM_PERCENT_RECEIVED, group = quantile)) + geom_jitter(size = 0.1, alpha = 0.1) + geom_smooth(aes(colour = factor(quantile)), size = 1.5) + coord_cartesian(ylim = c(0, 0.015)) + fte_theme() + labs(title="Percent of total awarded dollars per investigator\ngrouped by quantile", x="\nFiscal Year", y="Percent of awarded dollars\n") + geom_hline(yintercept=0, size=0.4, color="black") + scale_color_brewer(palette = "Set1")

```

```{r echo = FALSE}

quantiles %>%
  ggplot(aes(x = FY, y = SUM_PERCENT_RECEIVED, group = grant_dummy)) + geom_jitter(size = 0.1, alpha = 0.1) + geom_smooth(aes(colour = factor(grant_dummy)), size = 1.5) + coord_cartesian(ylim = c(0, 0.015)) + fte_theme() + labs(title="Percent of total awarded dollars per investigator\n grouped by investigators with 1 or more than 1 grant", x="\nFiscal Year", y="Percent of awarded dollars\n") + geom_hline(yintercept=0, size=0.4, color="black") + scale_color_brewer(palette = "Set1")

```

```{r echo = FALSE}


filter_target_quantile <- c("1", "2")

quantiles %>% 
  ggplot(aes(x = FY, y = NUMBER_OF_GRANTS, group = quantile)) + geom_jitter(aes(colour = factor(quantile)), size = 1, alpha = 0.3) + fte_theme() + labs(title="Total number of grants awarded per investigator", x="\nFiscal Year", y="Number of grants\n") + geom_hline(yintercept=0, size=0.4, color="black") + scale_color_brewer(palette = "Set1")

#
```

```{r echo = FALSE}

quantiles %>% 
  ggplot(aes(x = FY, y = SUM_COST_RECEIVED, group = grant_dummy)) + geom_jitter(size = 0.1, alpha = 0.2) + geom_smooth(aes(colour = factor(grant_dummy)), size = 2) + coord_cartesian(ylim = c(0, 1000000)) + fte_theme() + labs(title="Total dollars awarded per investigator", x="\nFiscal Year", y="Dollars awarded\n") + geom_hline(yintercept=0, size=0.4, color="black") + scale_color_brewer(palette = "Set1")

#some figures using the quantiles data

```

