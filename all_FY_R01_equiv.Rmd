---
title: "all_years"
author: "Nick_Fox"
date: "February 16, 2016"
output: html_document
---

```{r echo = FALSE}
#install.packages("dplyr")
#install.packages("ggplot2")
#install.packages("tidyr")
#install.packages("data.table")
#install.packages("stringr")
#install.packages("ineq")
#install.packages("RColorBrewer")
#install.packages("scales")
#install.packages("quantmod")
#install.packages("lubridate")
#install.packages("data.table")

suppressMessages(library(dplyr))
suppressMessages(library(tidyr))
suppressMessages(library(ggplot2))
suppressMessages(library(data.table))
suppressMessages(library(stringr))
suppressMessages(library(ineq))
suppressMessages(library(RColorBrewer))
suppressMessages(library(scales))
suppressMessages(library(grid))
suppressMessages(library(quantmod))
suppressMessages(library(lubridate))
suppressMessages(library(data.table))
#loads in all packages used in this analysis.  Find install code above.

```

```{r echo = FALSE}
Sem <- function(x) {
  sqrt(var(x)/length(x))
  }
#creates function to calculate the standard error of the mean, SEM




summarySE <- function(data=NULL, measurevar, groupvars=NULL, na.rm=FALSE,
                      conf.interval=.95, .drop=TRUE) {
    library(plyr)

    # New version of length which can handle NA's: if na.rm==T, don't count them
    length2 <- function (x, na.rm=FALSE) {
        if (na.rm) sum(!is.na(x))
        else       length(x)
    }

    # This does the summary. For each group's data frame, return a vector with
    # N, mean, and sd
    datac <- ddply(data, groupvars, .drop=.drop,
      .fun = function(xx, col) {
        c(N    = length2(xx[[col]], na.rm=na.rm),
          mean = mean   (xx[[col]], na.rm=na.rm),
          sd   = sd     (xx[[col]], na.rm=na.rm)
        )
      },
      measurevar
    )

    # Rename the "mean" column    
    datac <- rename(datac, c("mean" = measurevar))

    datac$se <- datac$sd / sqrt(datac$N)  # Calculate standard error of the mean

    # Confidence interval multiplier for standard error
    # Calculate t-statistic for confidence interval: 
    # e.g., if conf.interval is .95, use .975 (above/below), and use df=N-1
    ciMult <- qt(conf.interval/2 + .5, datac$N-1)
    datac$ci <- datac$se * ciMult

    return(datac)
}


normDataWithin <- function(data=NULL, idvar, measurevar, betweenvars=NULL,
                           na.rm=FALSE, .drop=TRUE) {
    library(plyr)

    # Measure var on left, idvar + between vars on right of formula.
    data.subjMean <- ddply(data, c(idvar, betweenvars), .drop=.drop,
     .fun = function(xx, col, na.rm) {
        c(subjMean = mean(xx[,col], na.rm=na.rm))
      },
      measurevar,
      na.rm
    )

    # Put the subject means with original data
    data <- merge(data, data.subjMean)

    # Get the normalized data in a new column
    measureNormedVar <- paste(measurevar, "_norm", sep="")
    data[,measureNormedVar] <- data[,measurevar] - data[,"subjMean"] +
                               mean(data[,measurevar], na.rm=na.rm)

    # Remove this subject mean column
    data$subjMean <- NULL

    return(data)
}


summarySEwithin <- function(data=NULL, measurevar, betweenvars=NULL, withinvars=NULL,
                            idvar=NULL, na.rm=FALSE, conf.interval=.95, .drop=TRUE) {

  # Ensure that the betweenvars and withinvars are factors
  factorvars <- vapply(data[, c(betweenvars, withinvars), drop=FALSE],
    FUN=is.factor, FUN.VALUE=logical(1))

  if (!all(factorvars)) {
    nonfactorvars <- names(factorvars)[!factorvars]
    message("Automatically converting the following non-factors to factors: ",
            paste(nonfactorvars, collapse = ", "))
    data[nonfactorvars] <- lapply(data[nonfactorvars], factor)
  }

  # Get the means from the un-normed data
  datac <- summarySE(data, measurevar, groupvars=c(betweenvars, withinvars),
                     na.rm=na.rm, conf.interval=conf.interval, .drop=.drop)

  # Drop all the unused columns (these will be calculated with normed data)
  datac$sd <- NULL
  datac$se <- NULL
  datac$ci <- NULL

  # Norm each subject's data
  ndata <- normDataWithin(data, idvar, measurevar, betweenvars, na.rm, .drop=.drop)

  # This is the name of the new column
  measurevar_n <- paste(measurevar, "_norm", sep="")

  # Collapse the normed data - now we can treat between and within vars the same
  ndatac <- summarySE(ndata, measurevar_n, groupvars=c(betweenvars, withinvars),
                      na.rm=na.rm, conf.interval=conf.interval, .drop=.drop)

  # Apply correction from Morey (2008) to the standard error and confidence interval
  #  Get the product of the number of conditions of within-S variables
  nWithinGroups    <- prod(vapply(ndatac[,withinvars, drop=FALSE], FUN=nlevels,
                           FUN.VALUE=numeric(1)))
  correctionFactor <- sqrt( nWithinGroups / (nWithinGroups-1) )

  # Apply the correction factor
  ndatac$sd <- ndatac$sd * correctionFactor
  ndatac$se <- ndatac$se * correctionFactor
  ndatac$ci <- ndatac$ci * correctionFactor

  # Combine the un-normed means with the normed results
  merge(datac, ndatac)
}

asNumeric <- function(x) as.numeric(as.character(x))
factorsNumeric <- function(d) modifyList(d, lapply(d[, sapply(d, is.factor)],   
                                                   asNumeric))
#functions that allow easy conversions of factors to numeric
```

```{r echo = FALSE}
read.url <- function(url, ...){
  tmpFile <- tempfile()
  download.file(url, destfile = tmpFile, method = "curl")
  url.data <- fread(tmpFile, ...)
  return(url.data)
}

#function to read url files (had used previously to collect online csv files)
```


```{r echo = FALSE}

fte_theme <- function() {
      
      # Generate the colors for the chart procedurally with RColorBrewer
      palette <- brewer.pal("Greys", n=9)
      color.background = palette[2]
      color.grid.major = palette[3]
      color.axis.text = palette[6]
      color.axis.title = palette[7]
      color.title = palette[9]
      
      # Begin construction of chart
      theme_bw(base_size=9) +
        
      # Set the entire chart region to a light gray color
      theme(panel.background=element_rect(fill=color.background, color=color.background)) +
      theme(plot.background=element_rect(fill=color.background, color=color.background)) +
      theme(panel.border=element_rect(color=color.background)) +
      
      # Format the grid
      theme(panel.grid.major=element_line(color=color.grid.major,size=.25)) +
      theme(panel.grid.minor=element_blank()) +
      theme(axis.ticks=element_blank()) +
      
      # Format the legend, but hide by default
      #theme(legend.position="none") +
      theme(legend.background = element_rect(fill=color.background)) +
      theme(legend.text = element_text(size=10,color=color.axis.title)) +
      
      # Set title and axis labels, and format these and tick marks
      theme(plot.title=element_text(color=color.title, size=16, vjust=1.25)) +
      theme(axis.text.x=element_text(size=10,color=color.axis.text)) +
      theme(axis.text.y=element_text(size=10,color=color.axis.text)) +
      theme(axis.title.x=element_text(size=12,color=color.axis.title, vjust=0.5)) +
      theme(axis.title.y=element_text(size=12,color=color.axis.title, vjust=0.5)) +
      
      # Plot margins
      theme(plot.margin = unit(c(0.35, 0.2, 0.3, 0.35), "cm"))
    }

#ggplot themes for figures to look a little more like 538 blog figures
```

```{r echo = FALSE}
#FOR MAC, use the WD below:
setwd("~/Dropbox/GitHub_master/data/NIH_awards")

```

```{r echo = FALSE}

fy2014 <- read.csv("RePORTER_PRJ_C_FY2014.csv", header = TRUE, stringsAsFactors = FALSE)
fy2013 <- read.csv("RePORTER_PRJ_C_FY2013.csv", header = TRUE, stringsAsFactors = FALSE)
fy2012 <- read.csv("RePORTER_PRJ_C_FY2012.csv", header = TRUE, stringsAsFactors = FALSE)
fy2011 <- read.csv("RePORTER_PRJ_C_FY2011.csv", header = TRUE, stringsAsFactors = FALSE)
fy2010 <- read.csv("RePORTER_PRJ_C_FY2010.csv", header = TRUE, stringsAsFactors = FALSE)
fy2009 <- read.csv("RePORTER_PRJ_C_FY2009.csv", header = TRUE, stringsAsFactors = FALSE)
fy2008 <- read.csv("RePORTER_PRJ_C_FY2008.csv", header = TRUE, stringsAsFactors = FALSE)
fy2007 <- read.csv("RePORTER_PRJ_C_FY2007.csv", header = TRUE, stringsAsFactors = FALSE)
fy2006 <- read.csv("RePORTER_PRJ_C_FY2006.csv", header = TRUE, stringsAsFactors = FALSE)
fy2005 <- read.csv("RePORTER_PRJ_C_FY2005.csv", header = TRUE, stringsAsFactors = FALSE)
fy2004 <- read.csv("RePORTER_PRJ_C_FY2004.csv", header = TRUE, stringsAsFactors = FALSE)
fy2003 <- read.csv("RePORTER_PRJ_C_FY2003.csv", header = TRUE, stringsAsFactors = FALSE)
fy2002 <- read.csv("RePORTER_PRJ_C_FY2002.csv", header = TRUE, stringsAsFactors = FALSE)
fy2001 <- read.csv("RePORTER_PRJ_C_FY2001.csv", header = TRUE, stringsAsFactors = FALSE)
fy2000 <- read.csv("RePORTER_PRJ_C_FY2000.csv", header = TRUE, stringsAsFactors = FALSE)

#read in all of the raw data

```


```{r echo = FALSE}
filter_target <- c("R01", "R23", "R29", "R37")

fy2014 <- fy2014 %>% 
  filter(ACTIVITY %in% filter_target) %>% 
  select(FY, ACTIVITY, ARRA_FUNDED, APPLICATION_ID, PI_IDS, TOTAL_COST, FULL_PROJECT_NUM)

fy2013 <- fy2013 %>% 
  filter(ACTIVITY %in% filter_target) %>% 
  select(FY, ACTIVITY, ARRA_FUNDED, APPLICATION_ID, PI_IDS, TOTAL_COST, FULL_PROJECT_NUM)

fy2012 <- fy2012 %>% 
  filter(ACTIVITY %in% filter_target) %>% 
  select(FY, ACTIVITY, ARRA_FUNDED, APPLICATION_ID, PI_IDS, TOTAL_COST, FULL_PROJECT_NUM)

fy2011 <- fy2011 %>% 
  filter(ACTIVITY %in% filter_target) %>% 
  select(FY, ACTIVITY, ARRA_FUNDED, APPLICATION_ID, PI_IDS, TOTAL_COST, FULL_PROJECT_NUM)

fy2010 <- fy2010 %>% 
  filter(ACTIVITY %in% filter_target) %>% 
  select(FY, ACTIVITY, ARRA_FUNDED, APPLICATION_ID, PI_IDS, TOTAL_COST, FULL_PROJECT_NUM) 

fy2009 <- fy2009 %>% 
  filter(ACTIVITY %in% filter_target) %>% 
  select(FY, ACTIVITY, ARRA_FUNDED, APPLICATION_ID, PI_IDS, TOTAL_COST, FULL_PROJECT_NUM)

fy2008 <- fy2008 %>% 
  filter(ACTIVITY %in% filter_target) %>% 
  select(FY, ACTIVITY, ARRA_FUNDED, APPLICATION_ID, PI_IDS, TOTAL_COST, FULL_PROJECT_NUM)

fy2007 <- fy2007 %>% 
  filter(ACTIVITY %in% filter_target) %>% 
  select(FY, ACTIVITY, ARRA_FUNDED, APPLICATION_ID, PI_IDS, TOTAL_COST, FULL_PROJECT_NUM)

fy2006 <- fy2006 %>% 
  filter(ACTIVITY %in% filter_target) %>% 
  select(FY, ACTIVITY, ARRA_FUNDED, APPLICATION_ID, PI_IDS, TOTAL_COST, FULL_PROJECT_NUM)

fy2005 <- fy2005 %>% 
  filter(ACTIVITY %in% filter_target) %>% 
  select(FY, ACTIVITY, ARRA_FUNDED, APPLICATION_ID, PI_IDS, TOTAL_COST, FULL_PROJECT_NUM)

fy2004 <- fy2004 %>% 
  filter(ACTIVITY %in% filter_target) %>% 
  select(FY, ACTIVITY, ARRA_FUNDED, APPLICATION_ID, PI_IDS, TOTAL_COST, FULL_PROJECT_NUM)

fy2003 <- fy2003 %>% 
  filter(ACTIVITY %in% filter_target) %>% 
  select(FY, ACTIVITY, ARRA_FUNDED, APPLICATION_ID, PI_IDS, TOTAL_COST, FULL_PROJECT_NUM)

fy2002 <- fy2002 %>% 
  filter(ACTIVITY %in% filter_target) %>% 
  select(FY, ACTIVITY, ARRA_FUNDED, APPLICATION_ID, PI_IDS, TOTAL_COST, FULL_PROJECT_NUM)

fy2001 <- fy2001 %>% 
  filter(ACTIVITY %in% filter_target) %>% 
  select(FY, ACTIVITY, ARRA_FUNDED, APPLICATION_ID, PI_IDS, TOTAL_COST, FULL_PROJECT_NUM)

fy2000 <- fy2000 %>% 
  filter(ACTIVITY %in% filter_target) %>% 
  select(FY, ACTIVITY, ARRA_FUNDED, APPLICATION_ID, PI_IDS, TOTAL_COST, FULL_PROJECT_NUM)

#select only R01 equivalent awards and the relevent columns
```

``` {r echo = FALSE}

R01_equiv <- bind_rows(fy2014, fy2013, fy2012, fy2011, fy2010, fy2009, fy2008, fy2007, fy2006, fy2005, fy2004, fy2003, fy2002, fy2001, fy2000)

#bind all years into one data frame

```

```{r echo = FALSE}

R01_equiv <- R01_equiv %>% 
  separate(col = PI_IDS, into = c("PI_1", "PI_2", "PI_3", "PI_4", "PI_5", "PI_6", "PI_7", "PI_8", "PI_9", "PI_10", "PI_11"), sep = "\\;")

R01_equiv[R01_equiv == ""] <- NA

R01_equiv <- as.data.frame(sapply(R01_equiv, gsub, pattern = "(.contact.)", replacement = ""), stringsAsFactors = FALSE)

R01_equiv$TOTAL_COST <- as.numeric(as.character(R01_equiv$TOTAL_COST))

R01_equiv <- R01_equiv %>% 
  mutate(PI_1_DUMMY = ifelse(!is.na(PI_1), 1, 0), PI_2_DUMMY = ifelse(!is.na(PI_2), 1, 0), PI_3_DUMMY = ifelse(!is.na(PI_3), 1, 0), PI_4_DUMMY = ifelse(!is.na(PI_4), 1, 0), PI_5_DUMMY = ifelse(!is.na(PI_5), 1, 0), PI_6_DUMMY = ifelse(!is.na(PI_6), 1, 0), PI_7_DUMMY = ifelse(!is.na(PI_7), 1, 0), PI_8_DUMMY = ifelse(!is.na(PI_8), 1, 0), PI_9_DUMMY = ifelse(!is.na(PI_9), 1, 0), PI_10_DUMMY = ifelse(!is.na(PI_10), 1, 0), PI_11_DUMMY = ifelse(!is.na(PI_11), 1, 0), TOTAL_PIS = PI_1_DUMMY + PI_2_DUMMY + PI_3_DUMMY + PI_4_DUMMY + PI_5_DUMMY + PI_6_DUMMY + PI_7_DUMMY + PI_8_DUMMY + PI_9_DUMMY + PI_10_DUMMY + PI_11_DUMMY)

R01_equiv <- R01_equiv %>%
  group_by(FY) %>% 
  filter(!is.na(TOTAL_COST)) %>% 
  mutate(TOTAL_DOLLARS = sum(TOTAL_COST), AVERAGE_PER_PI = TOTAL_DOLLARS / sum(TOTAL_PIS))

R01_equiv <- R01_equiv %>% 
  group_by(FY, APPLICATION_ID) %>% 
  mutate(COST_PER_PI = TOTAL_COST / TOTAL_PIS)

R01_equiv <- R01_equiv %>% 
  group_by(FY) %>% 
  mutate(PERCENT_COST_PER_PI = (COST_PER_PI / TOTAL_DOLLARS) * 100)

#seperating out PI column and calculating cost per PI per FY, average per PI per FY

```

```{r echo = FALSE}

PI_1 <- R01_equiv %>%
  mutate(PI = PI_1) %>%
  group_by(FY, PI) %>% 
  select(FY, ACTIVITY, ARRA_FUNDED, PI, COST_PER_PI, PERCENT_COST_PER_PI, FULL_PROJECT_NUM)

PI_2 <- R01_equiv %>%
  filter(!is.na(PI_2)) %>% 
  mutate(PI = PI_2) %>%
  group_by(FY, PI) %>% 
  select(FY, ACTIVITY, ARRA_FUNDED, PI, COST_PER_PI, PERCENT_COST_PER_PI, FULL_PROJECT_NUM)

PI_3 <- R01_equiv %>% 
  filter(!is.na(PI_3)) %>%
  mutate(PI = PI_3) %>%
  group_by(FY, PI) %>% 
  select(FY, ACTIVITY, ARRA_FUNDED, PI, COST_PER_PI, PERCENT_COST_PER_PI, FULL_PROJECT_NUM)

PI_4 <- R01_equiv %>% 
  filter(!is.na(PI_4)) %>%
  mutate(PI = PI_4) %>%
  group_by(FY, PI) %>% 
  select(FY, ACTIVITY, ARRA_FUNDED, PI, COST_PER_PI, PERCENT_COST_PER_PI, FULL_PROJECT_NUM)

PI_5 <- R01_equiv %>% 
  filter(!is.na(PI_5)) %>%
  mutate(PI = PI_5) %>%
  group_by(FY, PI) %>% 
  select(FY, ACTIVITY, ARRA_FUNDED, PI, COST_PER_PI, PERCENT_COST_PER_PI, FULL_PROJECT_NUM)

PI_6 <- R01_equiv %>% 
  filter(!is.na(PI_6)) %>%
  mutate(PI = PI_6) %>% 
  group_by(FY, PI) %>% 
  select(FY, ACTIVITY, ARRA_FUNDED, PI, COST_PER_PI, PERCENT_COST_PER_PI, FULL_PROJECT_NUM)

PI_7 <- R01_equiv %>% 
  filter(!is.na(PI_7)) %>%
  mutate(PI = PI_7) %>%
  group_by(FY, PI) %>% 
  select(FY, ACTIVITY, ARRA_FUNDED, PI, COST_PER_PI, PERCENT_COST_PER_PI, FULL_PROJECT_NUM)

PI_8 <- R01_equiv %>% 
  filter(!is.na(PI_8)) %>%
  mutate(PI = PI_8) %>%
  group_by(FY, PI) %>% 
  select(FY, ACTIVITY, ARRA_FUNDED, PI, COST_PER_PI, PERCENT_COST_PER_PI, FULL_PROJECT_NUM)

PI_9 <- R01_equiv %>% 
  filter(!is.na(PI_9)) %>%
  mutate(PI = PI_9) %>% 
  group_by(FY, PI) %>% 
  select(FY, ACTIVITY, ARRA_FUNDED, PI, COST_PER_PI, PERCENT_COST_PER_PI, FULL_PROJECT_NUM)

PI_10 <- R01_equiv %>% 
  filter(!is.na(PI_10)) %>%
  mutate(PI = PI_10) %>%
  group_by(FY, PI) %>% 
  select(FY, ACTIVITY, ARRA_FUNDED, PI, COST_PER_PI, PERCENT_COST_PER_PI, FULL_PROJECT_NUM)

PI_ALL <- bind_rows(PI_1, PI_2, PI_3, PI_4, PI_5, PI_6, PI_7, PI_8, PI_9, PI_10)

#get all authors, regardless of position in grant, into one column for further analysis
```

```{r echo = FALSE}

PI_ALL_BY_PI <- PI_ALL %>%
  group_by(FY, PI) %>% 
  mutate(SUM_COST_RECEIVED = sum(COST_PER_PI), NUMBER_OF_GRANTS = n(), SUM_PERCENT_RECEIVED = sum(PERCENT_COST_PER_PI)) %>% 
  distinct(PI)
#data frame with each author only appearing once per fiscal year.

PI_ALL_BY_GRANT_ID <- PI_ALL %>% 
  group_by(FY, FULL_PROJECT_NUM) %>% 
  mutate(NUMBER_OF_AUTHORS = n()) %>% 
  distinct(FULL_PROJECT_NUM)
```

```{r echo = FALSE}

quantiles <- PI_ALL_BY_PI %>% 
  group_by(FY) %>% 
  mutate(quantile = ntile(SUM_COST_RECEIVED, 5), grant_dummy = ifelse(NUMBER_OF_GRANTS == 1, 1, 2))

quantiles_average <- quantiles %>% 
  group_by(FY, quantile) %>% 
  mutate(average_sum_percent = mean(SUM_PERCENT_RECEIVED)) %>% 
  distinct(FY)


quantiles <- quantiles %>% 
  group_by(FY) %>% 
  mutate(FY_Gini = Gini(SUM_COST_RECEIVED))

quantiles_Gini <- quantiles %>% 
  distinct(FY)

#makes a few new data frames that include quintiles (population per year split into 5 based on SUM_COST_RECEIVED, which is the total dollars received per PI)
```

```{r echo = FALSE}

quantiles_test <- quantiles %>% 
  filter(NUMBER_OF_GRANTS == 1) %>% 
  group_by(FY) %>% 
  mutate(average_cost_one_grant = mean(SUM_COST_RECEIVED)) %>% 
  distinct(FY)

quantiles_test2 <- quantiles %>% 
  filter(NUMBER_OF_GRANTS != 1) %>% 
  group_by(FY) %>% 
  mutate(average_cost_two_or_more_grants = mean(SUM_COST_RECEIVED)) %>% 
  distinct(FY)
```

```{r echo = FALSE}

monthly_cpi <-read.csv("CPIAUCSL.csv", header = TRUE, stringsAsFactors = FALSE)

monthly_cpi$FY <- year(monthly_cpi$DATE)

yearly_cpi <- monthly_cpi %>% 
  group_by(FY) %>% 
  summarize(cpi = mean(VALUE))

yearly_cpi$adj_factor <- yearly_cpi$cpi/yearly_cpi$cpi[yearly_cpi$FY == 2000]

yearly_cpi$FY <- as.numeric(yearly_cpi$FY)

quantiles_test$FY <- as.numeric(quantiles_test$FY)


quantiles_test <- dplyr::left_join(quantiles_test, yearly_cpi, by = "FY")

quantiles_test$adj_factor <- 2-quantiles_test$adj_factor

quantiles_adjusted <- quantiles_test %>% 
  mutate(adjusted_average_cost = average_cost_one_grant * adj_factor)

#creates the adjustment factor for the quantiles_test data frame using the Consumer Price Index (CPI) - also created the final dataframe with a more useful name (adjusted)
```

```{r echo = FALSE}

quantiles_test2$FY <- as.numeric(quantiles_test2$FY)


quantiles_test2 <- dplyr::left_join(quantiles_test2, yearly_cpi, by = "FY")

quantiles_test2$adj_factor <- 2-quantiles_test2$adj_factor

quantiles_adjusted2 <- quantiles_test2 %>% 
  mutate(adjusted_average_cost_two_or_more = average_cost_two_or_more_grants * adj_factor)

```



```{R echo = FALSE}

R01_equiv_adjusted <- R01_equiv %>% 
  distinct(FY)
 
R01_equiv_adjusted$FY <- as.numeric(R01_equiv_adjusted$FY)

R01_equiv_adjusted <- dplyr::left_join(R01_equiv_adjusted, yearly_cpi, by = "FY")

R01_equiv_adjusted$adj_factor <- 2-R01_equiv_adjusted$adj_factor

R01_equiv_adjusted <- R01_equiv_adjusted %>% 
  mutate(adjusted_total_dollars = TOTAL_DOLLARS * adj_factor) %>% 
  select(FY, TOTAL_DOLLARS, adjusted_total_dollars)

#creates the adjustment factor for the R01_equiv data frame using the Consumer Price Index (CPI) - this is for total dollars dispersed by the NIH per year, and the adjusted, in constant year 2000 dollars.
```

```{r echo = FALSE}

PI_ALL_COUNT_PI_ONE_GRANT <- PI_ALL_BY_PI %>% 
  filter(NUMBER_OF_GRANTS == 1) %>% 
  group_by(FY) %>% 
  mutate(COUNT_PI = length(PI)) %>% 
  distinct(FY)

PI_ALL_COUNT_PI_MORE_GRANTS <- PI_ALL_BY_PI %>% 
  filter(NUMBER_OF_GRANTS != 1) %>% 
  group_by(FY) %>% 
  mutate(COUNT_PI_MORE_THAN_ONE = length(PI)) %>% 
  distinct(FY) %>% 
  select(FY, COUNT_PI_MORE_THAN_ONE)

PI_ALL_COUNT_PIS <- dplyr::left_join(PI_ALL_COUNT_PI_ONE_GRANT, PI_ALL_COUNT_PI_MORE_GRANTS, by = "FY")

#Makes a data frame that counts the number of unique investigators receiving R01 equivalent funds per year - used for a figure

```


# Federal Laboratory Funding in the 21st Century - A 15 Year Review
Authors: Nicholas Fox (Rutgers University) & Mariana Martins (Columbia University)

 <br>
 <br>
 
## Introduction

* Over the last century, research funding from the National Institutes of Health (NIH) have supported hundreds of thousands of independant scientists at more than 2,000 universities accross the country (CITATION - NIH website).  Nearly all of the NIH's funding is provided annually in the Departments of Labor, Health and Human Services, Education, and Related Agencies appropriations act.  This act is preceeded by the annual budget presented by the President and any Congressional budget resolutions.  Typically, the federal budget needs to be passed by October 1st.  If this does not happen, the government can pass short-term "continuing resolutions" (CR) to continue funding to government agencies.

* Since the year 2000, the federal budget has experienced surplus, deficit, and a historic recession.  Political battles in Congress have also caused budget deadlines to be missed, resulting in strings of CRs keeping federal agencies running.  Additionally, the budget sequestration of 2013 further hamstrung the budget of federal agencies due to the lack of the passing of a proper federal budget.

* The most common (and historically the oldest) source of public funding for independent investigators is the R01 (or R01 equivelent) award.  These awards allows an investigator to define the scientific objective of a project and provide funds for the specified project.  Projects are awarded to by the NIH to support specific areas of health-related research within a scope defined by the NIH and informed by the President and their scientific advisors.

* So far, it is unknown how these events have affected the NIH's ability to fund independent research laboratories.  This paper describes how R01 equivelent funding has changed over time since the beginning of the 21st century.

## Methods
### Data Collection
NIH budget files for fiscal years 2000 through 2014 were collected from the NIH RePORTER website's export tool, ExPORTER (website citation).  Fiscal year, NIH Application ID, Primary Investigator ID Number and Total Cost data was collected for each fiscal year.  Primary Investigator ID numbers were used to keep all data anonomyous.  Data for all R01-equivelent awards were collected, which include the activities R01, R23, R29, and R37, although not all awards may have been used in a given year.  The breakdown of which awards were used in each year can be seen in table 1 (MAKE TABLE 1).  Total cost information was associated with each investigator for each fiscal year.

Starting in 2007, R01-equivelent awards could have more than one primary investigator.  To account for this, the total cost dispersed per application was divided by the number of primary investigators and this number was associated with each individual investigator.  This operates on the assumption that award funds are being dispersed evenly to each investigator, but we realize in practice this may not be the case.

Per year, the number of grants per investigator was calculated.  This was a count of how many unique Application IDs were associated with each investigator ID.  The sum cost was calculated as the sum of the total cost associated with that investigator for each fiscal year.

Year 2000 adjusted dollars were calculated using the Consumer Price Index from the Bureau of Labor Statistics (CITATION - BLS link).  An adjustment factor was calculated and applied to the total cost amounts for each year after year 2000.


## Results
### Gini coefficient for inequality
The Gini coefficient has been used in previous literature to characterize inieuality in income distributions (CITATION).  The coefficient ranges from 0, where income is perfectly distributed among all group members, to 1, where income is perfectly concentrated with one group member.  A larger coefficient signifies a greater income disparity.  We used the Gini coefficient to describe R01-equivelent award disparity for each fiscal year, and it can be seen in Figure 1.

```{r echo = FALSE}

quantiles_Gini %>% 
  ggplot(aes(x = FY, y = FY_Gini, group = 1)) + geom_line(size = 2, colour = "#c0392b") + coord_cartesian(ylim = c(0.3, 0.36)) + fte_theme() + labs(title="Figure 1. Gini coefficient within R01-equivelent awards\n2000 - 2014", x="\nFiscal Year", y="Gini coefficient\n") + geom_hline(yintercept=0.3, size=0.4, color="black")

```

As seen above, the Gini coefficient steadily falls from year 2000 until year 2008, then increases in year 2009.  Following this increase, the coefficient again falls, though by year 2014 it is still higher than it's lowest point.

### Total NIH funds dispersed through R01-equivelent awards
Figure 2 below shows the total dollars dispersed by the NIH to R01-equvelent award recepients.  The red line shows the dollars reported, and the blue line shows the dollar amount in an inflation-adjusted year 2000 constant dollars.  

```{r echo = FALSE}

R01_equiv_adjusted$FY <- as.factor(R01_equiv_adjusted$FY)

R01_equiv_adjusted %>% 
  ggplot(aes(x = FY, y = TOTAL_DOLLARS, group = 1)) + geom_line(size = 2, colour = "#c0392b") + geom_line(aes(y = adjusted_total_dollars), size = 2, colour = "blue") + fte_theme() + labs(title="Figure 2. Amount dispersed by NIH per year\nfor R01-equivalent awards", x="\nFiscal Year", y="Dollars\n") + geom_hline(yintercept=6000000000, size=0.4, color="black") + geom_line(colour = "red") + geom_line(aes(y = adjusted_total_dollars), colour = "blue") + annotate("text",x=14,y=9500000000,label="Dollars",colour="#c0392b", size = 6) + annotate("text",x=14,y=7900000000,label="Adjusted\nDollars",colour="blue", size = 6)

```

As seen in the figure, in adjusted dollars, NIH funds awarded through R01-equvelent awards first peaked and then plateaued from years 2005-2008, then spiked in 2009.  In year 2000 constant dollars, this peak occured in 2004, before funds decreased to 2008.  In 2009, funds dispersed through these awards spiked, and was also high in 2010.  From 2011 on, the amount of dollars dispersed through these awards fell.


<br>
<br>
<br>
<br>



## Discussion




-------------------
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
-------------------













Now for some orphan figures:

<br>
<br>

```{r echo = FALSE}

quantiles_adjusted$FY <- as.factor(quantiles_adjusted$FY)

quantiles_adjusted %>% 
  ggplot(aes(x = FY, y = average_cost_one_grant, group = 1)) + geom_line(size = 2, colour = "#c0392b") + geom_line(aes(y = adjusted_average_cost), size = 2, colour = "blue") + fte_theme() + labs(title="Average amount dispersed to investigators\nwith 1 R01 equivalent award", x="\nFiscal Year", y="Average dollars\n") + geom_hline(yintercept=200000, size=0.4, color="black") + coord_cartesian(ylim = c(200000, 400000)) + annotate("text",x=14,y=325000,label="Dollars",colour="#c0392b", size = 6) + annotate("text",x=14,y=250000,label="Adjusted\nDollars",colour="blue", size = 6)

#average amount of grant dollars going to investigators who are only receiving one grant
```

<br>
<br>

```{r echo = FALSE}

PI_ALL_COUNT_PIS %>% 
  ggplot(aes(x = FY, y = COUNT_PI, group = 1)) + geom_line(size = 2, colour = "#c0392b") + geom_line(aes(y = COUNT_PI_MORE_THAN_ONE), size = 2, colour = "blue") + fte_theme() + labs(title="Number of unique investigators\nreceiving R01 equivalent funds per fiscal year", x="\nFiscal Year", y="Number of investigators\n") + geom_hline(yintercept=3000, size=0.4, color="black") + coord_cartesian(ylim = c(3000, 20000)) + annotate("text",x=13,y=15000,label="One grant",colour="#c0392b", size = 6) + annotate("text",x=13,y=8500,label="Two or more\ngrants",colour="blue", size = 6) 

```

<br>
<br>

```{r echo = FALSE}

quantiles_adjusted2$FY <- as.factor(quantiles_adjusted2$FY)

quantiles_adjusted2 %>% 
  ggplot(aes(x = FY, y = average_cost_two_or_more_grants, group = 1)) + geom_line(size = 2, colour = "#c0392b") + geom_line(aes(y = adjusted_average_cost_two_or_more), size = 2, colour = "blue") + fte_theme() + labs(title="Average amount dispersed to investigators\nwith more than 1 R01 equivalent award", x="\nFiscal Year", y="Average dollars\n") + geom_hline(yintercept=400000, size=0.4, color="black") + coord_cartesian(ylim = c(400000, 900000)) + annotate("text",x=14,y=850000,label="Dollars",colour="#c0392b", size = 6) + annotate("text",x=14,y=600000,label="Adjusted\nDollars",colour="blue", size = 6)

#average amount of grant dollars going to investigators who are only receiving one grant
```

<br>
<br>



```{r echo = FALSE}

quantiles_average %>%
  ggplot(aes(x = FY, y = average_sum_percent, group = quantile)) + geom_line(aes(colour = factor(quantile)), size = 2) + fte_theme() + labs(title="Percent of total awarded dollars per investigator\ngrouped by quantile", x="\nFiscal Year", y="Percent of awarded dollars\n") + geom_hline(yintercept=0.001, size=0.4, color="black") + scale_color_brewer(palette = "Set1")

```

<br>
<br>

```{r echo = FALSE}

quantiles %>% 
  ggplot(aes(x = FY, y = SUM_PERCENT_RECEIVED, group = quantile)) + geom_jitter(size = 0.1, alpha = 0.1) + geom_smooth(aes(colour = factor(quantile)), size = 1.5) + coord_cartesian(ylim = c(0, 0.015)) + fte_theme() + labs(title="Percent of total awarded dollars per investigator\ngrouped by quantile", x="\nFiscal Year", y="Percent of awarded dollars\n") + geom_hline(yintercept=0, size=0.4, color="black") + scale_color_brewer(palette = "Set1")

```

<br>
<br>

```{r echo = FALSE}

quantiles %>%
  ggplot(aes(x = FY, y = SUM_PERCENT_RECEIVED, group = grant_dummy)) + geom_jitter(size = 0.1, alpha = 0.1) + geom_smooth(aes(colour = factor(grant_dummy)), size = 1.5) + coord_cartesian(ylim = c(0, 0.015)) + fte_theme() + labs(title="Percent of total awarded dollars per investigator\n grouped by investigators with 1 or more than 1 grant", x="\nFiscal Year", y="Percent of awarded dollars\n") + geom_hline(yintercept=0, size=0.4, color="black") + scale_color_brewer(palette = "Set1")

```

<br>
<br>

```{r echo = FALSE}


filter_target_quantile <- c("1", "2")

quantiles %>% 
  ggplot(aes(x = FY, y = NUMBER_OF_GRANTS, group = quantile)) + geom_jitter(aes(colour = factor(quantile)), size = 1, alpha = 0.3) + fte_theme() + labs(title="Total number of grants awarded per investigator", x="\nFiscal Year", y="Number of grants\n") + geom_hline(yintercept=0, size=0.4, color="black") + scale_color_brewer(palette = "Set1")

#
```

<br>
<br>

```{r echo = FALSE}

quantiles %>% 
  ggplot(aes(x = FY, y = SUM_COST_RECEIVED, group = grant_dummy)) + geom_jitter(size = 0.1, alpha = 0.2) + geom_smooth(aes(colour = factor(grant_dummy)), size = 2) + coord_cartesian(ylim = c(0, 1000000)) + fte_theme() + labs(title="Total dollars awarded per investigator", x="\nFiscal Year", y="Dollars awarded\n") + geom_hline(yintercept=0, size=0.4, color="black") + scale_color_brewer(palette = "Set1")

#some figures using the quantiles data

```


```{r echo = FALSE}

PI_ALL_TEST <- PI_ALL %>% 
  mutate(ARRA_DUMMY = ifelse(ARRA_FUNDED == "Y", 1, 0))

PI_ALL_TEST <- PI_ALL_TEST %>% 
  group_by(FY, PI) %>% 
  mutate(TOTAL_ARRA = sum(ARRA_DUMMY)) %>% 
  select(FY, PI, TOTAL_ARRA)

GRANTS_AND_ARRA <- dplyr::left_join(PI_ALL_TEST, PI_ALL_BY_PI, by = c("FY", "PI"))

GRANTS_AND_ARRA <- GRANTS_AND_ARRA %>% 
  group_by(FY, PI) %>% 
  distinct(PI)


GRANTS_AND_ARRA <- GRANTS_AND_ARRA %>% 
  mutate(PERCENT_ARRA = ifelse(TOTAL_ARRA >= 1, (TOTAL_ARRA / NUMBER_OF_GRANTS)*100, 0))


GRANTS_AND_ARRA %>% 
  filter(NUMBER_OF_GRANTS == 1) %>% 
  ggplot(aes(x = FY, y = PERCENT_ARRA, group = 1 )) + geom_jitter()


```

