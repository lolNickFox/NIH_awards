---
title: "all_years"
author: "Nick_Fox"
date: "February 16, 2016"
output: html_document
---

```{r echo = FALSE}
#install.packages("dplyr")
#install.packages("ggplot2")
#install.packages("tidyr")
#install.packages("data.table")
#install.packages("stringr")



library(dplyr)
library(tidyr)
library(ggplot2)
library(data.table)
library(stringr)
#loads in all packages used in this analysis.  Find install code above.


Sem <- function(x) {
  sqrt(var(x)/length(x))
  }
#creates function to calculate the standard error of the mean, SEM




summarySE <- function(data=NULL, measurevar, groupvars=NULL, na.rm=FALSE,
                      conf.interval=.95, .drop=TRUE) {
    library(plyr)

    # New version of length which can handle NA's: if na.rm==T, don't count them
    length2 <- function (x, na.rm=FALSE) {
        if (na.rm) sum(!is.na(x))
        else       length(x)
    }

    # This does the summary. For each group's data frame, return a vector with
    # N, mean, and sd
    datac <- ddply(data, groupvars, .drop=.drop,
      .fun = function(xx, col) {
        c(N    = length2(xx[[col]], na.rm=na.rm),
          mean = mean   (xx[[col]], na.rm=na.rm),
          sd   = sd     (xx[[col]], na.rm=na.rm)
        )
      },
      measurevar
    )

    # Rename the "mean" column    
    datac <- rename(datac, c("mean" = measurevar))

    datac$se <- datac$sd / sqrt(datac$N)  # Calculate standard error of the mean

    # Confidence interval multiplier for standard error
    # Calculate t-statistic for confidence interval: 
    # e.g., if conf.interval is .95, use .975 (above/below), and use df=N-1
    ciMult <- qt(conf.interval/2 + .5, datac$N-1)
    datac$ci <- datac$se * ciMult

    return(datac)
}


normDataWithin <- function(data=NULL, idvar, measurevar, betweenvars=NULL,
                           na.rm=FALSE, .drop=TRUE) {
    library(plyr)

    # Measure var on left, idvar + between vars on right of formula.
    data.subjMean <- ddply(data, c(idvar, betweenvars), .drop=.drop,
     .fun = function(xx, col, na.rm) {
        c(subjMean = mean(xx[,col], na.rm=na.rm))
      },
      measurevar,
      na.rm
    )

    # Put the subject means with original data
    data <- merge(data, data.subjMean)

    # Get the normalized data in a new column
    measureNormedVar <- paste(measurevar, "_norm", sep="")
    data[,measureNormedVar] <- data[,measurevar] - data[,"subjMean"] +
                               mean(data[,measurevar], na.rm=na.rm)

    # Remove this subject mean column
    data$subjMean <- NULL

    return(data)
}


summarySEwithin <- function(data=NULL, measurevar, betweenvars=NULL, withinvars=NULL,
                            idvar=NULL, na.rm=FALSE, conf.interval=.95, .drop=TRUE) {

  # Ensure that the betweenvars and withinvars are factors
  factorvars <- vapply(data[, c(betweenvars, withinvars), drop=FALSE],
    FUN=is.factor, FUN.VALUE=logical(1))

  if (!all(factorvars)) {
    nonfactorvars <- names(factorvars)[!factorvars]
    message("Automatically converting the following non-factors to factors: ",
            paste(nonfactorvars, collapse = ", "))
    data[nonfactorvars] <- lapply(data[nonfactorvars], factor)
  }

  # Get the means from the un-normed data
  datac <- summarySE(data, measurevar, groupvars=c(betweenvars, withinvars),
                     na.rm=na.rm, conf.interval=conf.interval, .drop=.drop)

  # Drop all the unused columns (these will be calculated with normed data)
  datac$sd <- NULL
  datac$se <- NULL
  datac$ci <- NULL

  # Norm each subject's data
  ndata <- normDataWithin(data, idvar, measurevar, betweenvars, na.rm, .drop=.drop)

  # This is the name of the new column
  measurevar_n <- paste(measurevar, "_norm", sep="")

  # Collapse the normed data - now we can treat between and within vars the same
  ndatac <- summarySE(ndata, measurevar_n, groupvars=c(betweenvars, withinvars),
                      na.rm=na.rm, conf.interval=conf.interval, .drop=.drop)

  # Apply correction from Morey (2008) to the standard error and confidence interval
  #  Get the product of the number of conditions of within-S variables
  nWithinGroups    <- prod(vapply(ndatac[,withinvars, drop=FALSE], FUN=nlevels,
                           FUN.VALUE=numeric(1)))
  correctionFactor <- sqrt( nWithinGroups / (nWithinGroups-1) )

  # Apply the correction factor
  ndatac$sd <- ndatac$sd * correctionFactor
  ndatac$se <- ndatac$se * correctionFactor
  ndatac$ci <- ndatac$ci * correctionFactor

  # Combine the un-normed means with the normed results
  merge(datac, ndatac)
}

asNumeric <- function(x) as.numeric(as.character(x))
factorsNumeric <- function(d) modifyList(d, lapply(d[, sapply(d, is.factor)],   
                                                   asNumeric))
#functions that allow easy conversions of factors to numeric

#FOR MAC, use the WD below:
setwd("~/Dropbox/GitHub_master/data/NIH_awards")

```

```{r echo = FALSE}

fy2014 <- read.csv("RePORTER_PRJ_C_FY2014.csv", header = TRUE, stringsAsFactors = FALSE)
fy2013 <- read.csv("RePORTER_PRJ_C_FY2013.csv", header = TRUE, stringsAsFactors = FALSE)
fy2012 <- read.csv("RePORTER_PRJ_C_FY2012.csv", header = TRUE, stringsAsFactors = FALSE)
fy2011 <- read.csv("RePORTER_PRJ_C_FY2011.csv", header = TRUE, stringsAsFactors = FALSE)
fy2010 <- read.csv("RePORTER_PRJ_C_FY2010.csv", header = TRUE, stringsAsFactors = FALSE)
fy2009 <- read.csv("RePORTER_PRJ_C_FY2009.csv", header = TRUE, stringsAsFactors = FALSE)
fy2008 <- read.csv("RePORTER_PRJ_C_FY2008.csv", header = TRUE, stringsAsFactors = FALSE)
fy2007 <- read.csv("RePORTER_PRJ_C_FY2007.csv", header = TRUE, stringsAsFactors = FALSE)
fy2006 <- read.csv("RePORTER_PRJ_C_FY2006.csv", header = TRUE, stringsAsFactors = FALSE)
fy2005 <- read.csv("RePORTER_PRJ_C_FY2005.csv", header = TRUE, stringsAsFactors = FALSE)
fy2004 <- read.csv("RePORTER_PRJ_C_FY2004.csv", header = TRUE, stringsAsFactors = FALSE)
fy2003 <- read.csv("RePORTER_PRJ_C_FY2003.csv", header = TRUE, stringsAsFactors = FALSE)
fy2002 <- read.csv("RePORTER_PRJ_C_FY2002.csv", header = TRUE, stringsAsFactors = FALSE)
fy2001 <- read.csv("RePORTER_PRJ_C_FY2001.csv", header = TRUE, stringsAsFactors = FALSE)
fy2000 <- read.csv("RePORTER_PRJ_C_FY2000.csv", header = TRUE, stringsAsFactors = FALSE)

#read in all of the raw data

```


```{r echo = FALSE}
filter_target <- c("R01", "R23", "R29", "R37")

fy2014 <- fy2014 %>% 
  filter(ACTIVITY %in% filter_target) %>% 
  select(FY, ACTIVITY, APPLICATION_ID, PI_IDS, TOTAL_COST)

fy2013 <- fy2013 %>% 
  filter(ACTIVITY %in% filter_target) %>% 
  select(FY, ACTIVITY, APPLICATION_ID, PI_IDS, TOTAL_COST)

fy2012 <- fy2012 %>% 
  filter(ACTIVITY %in% filter_target) %>% 
  select(FY, ACTIVITY, APPLICATION_ID, PI_IDS, TOTAL_COST)

fy2011 <- fy2011 %>% 
  filter(ACTIVITY %in% filter_target) %>% 
  select(FY, ACTIVITY, APPLICATION_ID, PI_IDS, TOTAL_COST)

fy2010 <- fy2010 %>% 
  filter(ACTIVITY %in% filter_target) %>% 
  select(FY, ACTIVITY, APPLICATION_ID, PI_IDS, TOTAL_COST)

fy2009 <- fy2009 %>% 
  filter(ACTIVITY %in% filter_target) %>% 
  select(FY, ACTIVITY, APPLICATION_ID, PI_IDS, TOTAL_COST)

fy2008 <- fy2008 %>% 
  filter(ACTIVITY %in% filter_target) %>% 
  select(FY, ACTIVITY, APPLICATION_ID, PI_IDS, TOTAL_COST)

fy2007 <- fy2007 %>% 
  filter(ACTIVITY %in% filter_target) %>% 
  select(FY, ACTIVITY, APPLICATION_ID, PI_IDS, TOTAL_COST)

fy2006 <- fy2006 %>% 
  filter(ACTIVITY %in% filter_target) %>% 
  select(FY, ACTIVITY, APPLICATION_ID, PI_IDS, TOTAL_COST)

fy2005 <- fy2005 %>% 
  filter(ACTIVITY %in% filter_target) %>% 
  select(FY, ACTIVITY, APPLICATION_ID, PI_IDS, TOTAL_COST)

fy2004 <- fy2004 %>% 
  filter(ACTIVITY %in% filter_target) %>% 
  select(FY, ACTIVITY, APPLICATION_ID, PI_IDS, TOTAL_COST)

fy2003 <- fy2003 %>% 
  filter(ACTIVITY %in% filter_target) %>% 
  select(FY, ACTIVITY, APPLICATION_ID, PI_IDS, TOTAL_COST)

fy2002 <- fy2002 %>% 
  filter(ACTIVITY %in% filter_target) %>% 
  select(FY, ACTIVITY, APPLICATION_ID, PI_IDS, TOTAL_COST)

fy2001 <- fy2001 %>% 
  filter(ACTIVITY %in% filter_target) %>% 
  select(FY, ACTIVITY, APPLICATION_ID, PI_IDS, TOTAL_COST)

fy2000 <- fy2000 %>% 
  filter(ACTIVITY %in% filter_target) %>% 
  select(FY, ACTIVITY, APPLICATION_ID, PI_IDS, TOTAL_COST)

#select only R01 equivalent awards and the relevent columns
```

``` {r echo = FALSE}

R01_equiv <- bind_rows(fy2014, fy2013, fy2012, fy2011, fy2010, fy2009, fy2008, fy2007, fy2006, fy2005, fy2004, fy2003, fy2002, fy2001, fy2000)

#bind all years into one data frame

```

```{r echo = FALSE}

R01_equiv <- R01_equiv %>% 
  separate(col = PI_IDS, into = c("PI_1", "PI_2", "PI_3", "PI_4", "PI_5", "PI_6", "PI_7", "PI_8", "PI_9", "PI_10", "PI_11"), sep = "\\;")

R01_equiv[R01_equiv == ""] <- NA

R01_equiv <- as.data.frame(sapply(R01_equiv, gsub, pattern = "(.contact.)", replacement = ""), stringsAsFactors = FALSE)

R01_equiv$TOTAL_COST <- as.numeric(as.character(R01_equiv$TOTAL_COST))

R01_equiv <- R01_equiv %>% 
  mutate(PI_1_DUMMY = ifelse(!is.na(PI_1), 1, 0), PI_2_DUMMY = ifelse(!is.na(PI_2), 1, 0), PI_3_DUMMY = ifelse(!is.na(PI_3), 1, 0), PI_4_DUMMY = ifelse(!is.na(PI_4), 1, 0), PI_5_DUMMY = ifelse(!is.na(PI_5), 1, 0), PI_6_DUMMY = ifelse(!is.na(PI_6), 1, 0), PI_7_DUMMY = ifelse(!is.na(PI_7), 1, 0), PI_8_DUMMY = ifelse(!is.na(PI_8), 1, 0), PI_9_DUMMY = ifelse(!is.na(PI_9), 1, 0), PI_10_DUMMY = ifelse(!is.na(PI_10), 1, 0), PI_11_DUMMY = ifelse(!is.na(PI_11), 1, 0), TOTAL_PIS = PI_1_DUMMY + PI_2_DUMMY + PI_3_DUMMY + PI_4_DUMMY + PI_5_DUMMY + PI_6_DUMMY + PI_7_DUMMY + PI_8_DUMMY + PI_9_DUMMY + PI_10_DUMMY + PI_11_DUMMY)

R01_equiv <- R01_equiv %>%
  group_by(FY) %>% 
  filter(!is.na(TOTAL_COST)) %>% 
  mutate(TOTAL_DOLLARS = sum(TOTAL_COST), AVERAGE_PER_PI = TOTAL_DOLLARS / sum(TOTAL_PIS))

R01_equiv <- R01_equiv %>% 
  group_by(FY, APPLICATION_ID) %>% 
  mutate(COST_PER_PI = TOTAL_COST / TOTAL_PIS)

R01_equiv <- R01_equiv %>% 
  group_by(FY) %>% 
  mutate(PERCENT_COST_PER_PI = (COST_PER_PI / TOTAL_DOLLARS) * 100)

#seperating out PI column and calculating cost per PI per FY, average per PI per FY

```

```{r echo = FALSE}

PI_1 <- R01_equiv %>%
  mutate(PI = PI_1) %>%
  group_by(FY, PI) %>% 
  select(FY, ACTIVITY, PI, COST_PER_PI, PERCENT_COST_PER_PI)

PI_2 <- R01_equiv %>%
  filter(!is.na(PI_2)) %>% 
  mutate(PI = PI_2) %>%
  group_by(FY, PI) %>% 
  select(FY, ACTIVITY, PI, COST_PER_PI, PERCENT_COST_PER_PI)

PI_3 <- R01_equiv %>% 
  filter(!is.na(PI_3)) %>%
  mutate(PI = PI_3) %>%
  group_by(FY, PI) %>% 
  select(FY, ACTIVITY, PI, COST_PER_PI, PERCENT_COST_PER_PI)

PI_4 <- R01_equiv %>% 
  filter(!is.na(PI_4)) %>%
  mutate(PI = PI_4) %>%
  group_by(FY, PI) %>% 
  select(FY, ACTIVITY, PI, COST_PER_PI, PERCENT_COST_PER_PI)

PI_5 <- R01_equiv %>% 
  filter(!is.na(PI_5)) %>%
  mutate(PI = PI_5) %>%
  group_by(FY, PI) %>% 
  select(FY, ACTIVITY, PI, COST_PER_PI, PERCENT_COST_PER_PI)

PI_6 <- R01_equiv %>% 
  filter(!is.na(PI_6)) %>%
  mutate(PI = PI_6) %>% 
  group_by(FY, PI) %>% 
  select(FY, ACTIVITY, PI, COST_PER_PI, PERCENT_COST_PER_PI)

PI_7 <- R01_equiv %>% 
  filter(!is.na(PI_7)) %>%
  mutate(PI = PI_7) %>%
  group_by(FY, PI) %>% 
  select(FY, ACTIVITY, PI, COST_PER_PI, PERCENT_COST_PER_PI)

PI_8 <- R01_equiv %>% 
  filter(!is.na(PI_8)) %>%
  mutate(PI = PI_8) %>%
  group_by(FY, PI) %>% 
  select(FY, ACTIVITY, PI, COST_PER_PI, PERCENT_COST_PER_PI)

PI_9 <- R01_equiv %>% 
  filter(!is.na(PI_9)) %>%
  mutate(PI = PI_9) %>% 
  group_by(FY, PI) %>% 
  select(FY, ACTIVITY, PI, COST_PER_PI, PERCENT_COST_PER_PI)

PI_10 <- R01_equiv %>% 
  filter(!is.na(PI_10)) %>%
  mutate(PI = PI_10) %>%
  group_by(FY, PI) %>% 
  select(FY, ACTIVITY, PI, COST_PER_PI, PERCENT_COST_PER_PI)

PI_ALL <- bind_rows(PI_1, PI_2, PI_3, PI_4, PI_5, PI_6, PI_7, PI_8, PI_9, PI_10)

#get all authors, regardless of position in grant, into one column for further analysis
```

```{r echo = FALSE}

PI_ALL <- PI_ALL %>%
  group_by(FY, PI) %>% 
  mutate(SUM_COST_RECEIVED = sum(COST_PER_PI), NUMBER_OF_GRANTS = n(), SUM_PERCENT_RECEIVED = sum(PERCENT_COST_PER_PI)) %>% 
  distinct(PI)

#data frame with each author only appearing once per fiscal year.
```

```{r echo = FALSE}

quantiles <- PI_ALL %>% 
  group_by(FY) %>% 
  mutate(quantile = ntile(SUM_PERCENT_RECEIVED, 5))

quantiles_average <- quantiles %>% 
  group_by(FY, quantile) %>% 
  mutate(average_sum_percent = mean(SUM_PERCENT_RECEIVED)) %>% 
  distinct(FY)
```

```{r echo = FALSE}
quantiles_average %>% 
  ggplot(aes(x = FY, y = average_sum_percent, group = quantile)) + geom_point(aes(colour = factor(quantile)), size = 3) + geom_line(aes(colour = factor(quantile)), size = 2)


quantiles %>% 
  ggplot(aes(x = FY, y = SUM_PERCENT_RECEIVED, group = quantile)) + geom_point(aes(colour = factor(quantile)), size = 0.25, alpha = 0.0) + geom_smooth(aes(colour = factor(quantile)), size = 2) + coord_cartesian(ylim = c(0, 0.012))


quantiles %>% 
  ggplot(aes(x = FY, y = NUMBER_OF_GRANTS, group = quantile)) + geom_jitter(aes(colour = factor(quantile)), size = 0.25, alpha = 0.5)




#some figures using the quantiles data

```



